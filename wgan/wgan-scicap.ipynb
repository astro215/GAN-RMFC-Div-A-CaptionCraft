{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a564be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:09.454642Z",
     "iopub.status.busy": "2024-04-03T04:39:09.454369Z",
     "iopub.status.idle": "2024-04-03T04:39:14.345048Z",
     "shell.execute_reply": "2024-04-03T04:39:14.343808Z"
    },
    "papermill": {
     "duration": 4.897878,
     "end_time": "2024-04-03T04:39:14.347568",
     "exception": false,
     "start_time": "2024-04-03T04:39:09.449690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp -r /kaggle/input/dataset-gans-train/code /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c12ea32",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:14.356417Z",
     "iopub.status.busy": "2024-04-03T04:39:14.355642Z",
     "iopub.status.idle": "2024-04-03T04:39:15.314414Z",
     "shell.execute_reply": "2024-04-03T04:39:15.313220Z"
    },
    "papermill": {
     "duration": 0.966092,
     "end_time": "2024-04-03T04:39:15.317352",
     "exception": false,
     "start_time": "2024-04-03T04:39:14.351260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp -r /kaggle/input/dataset-gans-train/config-kaggle.json /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608087a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:15.326028Z",
     "iopub.status.busy": "2024-04-03T04:39:15.325210Z",
     "iopub.status.idle": "2024-04-03T04:39:16.310184Z",
     "shell.execute_reply": "2024-04-03T04:39:16.309000Z"
    },
    "papermill": {
     "duration": 0.991586,
     "end_time": "2024-04-03T04:39:16.312504",
     "exception": false,
     "start_time": "2024-04-03T04:39:15.320918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm /kaggle/working/code/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fe200e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:16.320653Z",
     "iopub.status.busy": "2024-04-03T04:39:16.320341Z",
     "iopub.status.idle": "2024-04-03T04:39:16.328577Z",
     "shell.execute_reply": "2024-04-03T04:39:16.327675Z"
    },
    "papermill": {
     "duration": 0.014593,
     "end_time": "2024-04-03T04:39:16.330431",
     "exception": false,
     "start_time": "2024-04-03T04:39:16.315838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/config-kaggle.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/config-kaggle.json\n",
    "{\n",
    "    \"data\": {\n",
    "        \"train\": {\n",
    "            \"captions\": \"/kaggle/input/dataset-gans-train/dataset-1t/captions/train.en\",\n",
    "            \"features\": \"/kaggle/input/dataset-gans-train/dataset-1t/features/train.npy\",\n",
    "            \"links\": \"/kaggle/input/dataset-gans-train/dataset-1t/links/train.txt\"\n",
    "        },\n",
    "        \"beam\": {\n",
    "            \"captions\": \"/kaggle/input/dataset-gans-train/dataset-1t/captions/val.en\",\n",
    "            \"features\": \"/kaggle/input/dataset-gans-train/dataset-1t/features/val.npy\",\n",
    "            \"links\": \"/kaggle/input/dataset-gans-train/dataset-1t/links/beam.txt\"\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"captions\": \"/kaggle/input/dataset-gans-train/dataset-1t/captions/test.en\",\n",
    "            \"features\": \"/kaggle/input/dataset-gans-train/dataset-1t/features/test.npy\",\n",
    "            \"links\": \"/kaggle/input/dataset-gans-train/dataset-1t/links/beam.txt\"\n",
    "        },\n",
    "        \"images\": \"cocodataset/images\",\n",
    "        \"vocab\": \"/kaggle/input/dataset-gans-train/dataset-1t/vocab.en\"\n",
    "    },\n",
    "    \"seed\": 1561478941,\n",
    "    \"max_epoch\": 30,\n",
    "    \"logging\": {\n",
    "        \"activate\": true,\n",
    "        \"output_folder\": \"results\"\n",
    "    },\n",
    "    \"cuda\": {\n",
    "        \"ngpu\": 2,\n",
    "        \"device\": \"cuda:0\"\n",
    "    },\n",
    "    \"sampler\": {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 128,\n",
    "            \"max_len\": 20\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"batch_size\": 32,\n",
    "            \"max_len\": 20\n",
    "        },\n",
    "        \"beam\": {\n",
    "            \"batch_size\": 128,\n",
    "            \"drop_last\": false\n",
    "        }\n",
    "    },\n",
    "    \"iterator\": {\n",
    "        \"train\": {\n",
    "            \"pin_memory\": false,\n",
    "            \"num_workers\": 0\n",
    "        },\n",
    "        \"beam\": {\n",
    "            \"pin_memory\": false,\n",
    "            \"num_workers\": 0\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"pin_memory\": false,\n",
    "            \"num_workers\": 0\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"embeddings\": \"/kaggle/input/dataset-gans-train/dataset-1t/embeddings/glove.6B.300d.txt\",\n",
    "        \"emb_dim\": 300,\n",
    "        \"dec_dim\": 256,\n",
    "        \"gradient_weight\": 10,\n",
    "        \"clip\": 1.0,\n",
    "        \"feature_size\": 2048,\n",
    "        \"optimizers\": {\n",
    "            \"lr\": 0.002,\n",
    "            \"weight_decay\": 1e-05,\n",
    "            \"betas\": {\n",
    "                \"min\": 0.5,\n",
    "                \"max\": 0.999\n",
    "            }\n",
    "        },\n",
    "        \"generator\": {\n",
    "            \"dropout_emb\": 0.0,\n",
    "            \"dropout_type\": \"local\",\n",
    "            \"dropout_state\": 0.5,\n",
    "            \"train_iteration\": 9,\n",
    "            \"dec_init_type\": \"zero\",\n",
    "            \"att_activ\": \"tanh\"\n",
    "        },\n",
    "        \"discriminator\": {\n",
    "            \"dec_init_type\": \"zero\",\n",
    "            \"att_activ\": \"relu\"\n",
    "        }\n",
    "    },\n",
    "    \"beam_search\": {\n",
    "        \"beam_size\": 5,\n",
    "        \"max_len\": 25\n",
    "    },\n",
    "    \"BLEU\": {\n",
    "        \"max_bleu\": 4\n",
    "    },\n",
    "    \"load_dict\": \"output_epoch29_bleu0.07394183608962669\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31fc41a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:16.337709Z",
     "iopub.status.busy": "2024-04-03T04:39:16.337473Z",
     "iopub.status.idle": "2024-04-03T04:39:17.388886Z",
     "shell.execute_reply": "2024-04-03T04:39:17.387270Z"
    },
    "papermill": {
     "duration": 1.058116,
     "end_time": "2024-04-03T04:39:17.391672",
     "exception": false,
     "start_time": "2024-04-03T04:39:16.333556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  3 04:39:17 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   33C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b42cb53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:17.431624Z",
     "iopub.status.busy": "2024-04-03T04:39:17.431242Z",
     "iopub.status.idle": "2024-04-03T04:39:17.442392Z",
     "shell.execute_reply": "2024-04-03T04:39:17.441203Z"
    },
    "papermill": {
     "duration": 0.021524,
     "end_time": "2024-04-03T04:39:17.444655",
     "exception": false,
     "start_time": "2024-04-03T04:39:17.423131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/code/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/code/main.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import utils.explorer_helper as exh\n",
    "import utils.vocab as uvoc\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "import subprocess  # Import subprocess for GPU usage monitoring\n",
    "from datasets.captioning import CaptioningDataset\n",
    "from metrics.scores import bleu_score, prepare_references\n",
    "from metrics.search import beam_search, max_search\n",
    "from models.wgan import WGAN\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import check_args, fix_seed\n",
    "\n",
    "# Function to get GPU usage using nvidia-smi\n",
    "def get_gpu_usage():\n",
    "    output = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,nounits'])\n",
    "    gpu_usage = [int(x) for x in output.decode('utf-8').strip().split('\\n')[1].split(',')]\n",
    "    return gpu_usage\n",
    "\n",
    "def run(args):\n",
    "    config = exh.load_json(args.CONFIG)\n",
    "    logging = config['logging']['activate']\n",
    "    if logging:\n",
    "        exh.create_directory(\"output\")\n",
    "        output = os.path.join(\"output\", config['logging']['output_folder'])\n",
    "        exh.create_directory(output)\n",
    "\n",
    "    torch.cuda.init()\n",
    "    device = torch.device(config['cuda']['device'] if (torch.cuda.is_available() and config['cuda']['ngpu'] > 0) else \"cpu\")\n",
    "    seed = fix_seed(config['seed'])\n",
    "    vocab = exh.load_json(config['data']['vocab'])\n",
    "    references = exh.read_file(config['data']['beam']['captions'])\n",
    "    references = prepare_references(references)\n",
    "\n",
    "    training_dataset = CaptioningDataset(config['data']['train'], \"train\", vocab, config['sampler']['train'])\n",
    "    train_iterator = DataLoader(\n",
    "        training_dataset,\n",
    "        batch_sampler=training_dataset.sampler,\n",
    "        collate_fn=training_dataset.collate_fn,\n",
    "        pin_memory=config['iterator']['train']['pin_memory'],\n",
    "        num_workers=config['iterator']['train']['num_workers']\n",
    "    )\n",
    "    beam_dataset = CaptioningDataset(config['data']['beam'], \"beam\", vocab, config['sampler']['beam'])\n",
    "    beam_iterator = DataLoader(\n",
    "        beam_dataset,\n",
    "        batch_sampler=beam_dataset.sampler,\n",
    "        collate_fn=beam_dataset.collate_fn,\n",
    "        pin_memory=config['iterator']['beam']['pin_memory'],\n",
    "        num_workers=config['iterator']['beam']['num_workers']\n",
    "    )\n",
    "\n",
    "    weights = None\n",
    "    if len(config['model']['embeddings']) > 0:\n",
    "        weights = uvoc.init_weights(vocab, config['model']['emb_dim'])\n",
    "        uvoc.glove_weights(weights, config['model']['embeddings'], vocab)\n",
    "\n",
    "    model = WGAN(len(vocab['token_list']), config['model'], weights)\n",
    "    model.reset_parameters()\n",
    "\n",
    "    lr = config['model']['optimizers']['lr']\n",
    "    betas = (config['model']['optimizers']['betas']['min'], config['model']['optimizers']['betas']['max'])\n",
    "    weight_decay = config['model']['optimizers']['weight_decay']\n",
    "\n",
    "    optim_D = optim.Adam(model.D.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "    optim_G = optim.Adam(model.G.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    fix_seed(config['seed'] + 1)\n",
    "\n",
    "    generator_trained = config['model']['generator']['train_iteration']\n",
    "\n",
    "    scores = {\n",
    "        \"BLEU\": [],\n",
    "        \"G_loss_train\": [],\n",
    "        \"D_loss_train\": []\n",
    "    }\n",
    "    max_bleu = config['BLEU']['max_bleu']\n",
    "    bleus = [[]] * max_bleu\n",
    "    best_bleu = (0, 1)\n",
    "\n",
    "    model.train(True)\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    epoch = 1\n",
    "    while epoch <= 30:\n",
    "        secs = time.time()\n",
    "        print(\"Starting Epoch {}\".format(epoch))\n",
    "\n",
    "        iteration = 1\n",
    "\n",
    "        d_batch = 0\n",
    "        g_batch = 0\n",
    "        d_loss = 0\n",
    "        g_loss = 0\n",
    "        train_iterator = tqdm(train_iterator, desc=\"Training\", leave=False)  # Add tqdm for training progress bar\n",
    "        for batch in train_iterator:\n",
    "            batch.device(device)\n",
    "\n",
    "            out = model(batch, optim_G, optim_D, epoch, iteration)\n",
    "\n",
    "            d_loss += out['D_loss']\n",
    "            d_batch += 1\n",
    "            g_loss += out['G_loss']\n",
    "            g_batch += 1\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            # Monitor GPU usage\n",
    "            gpu_usage = get_gpu_usage()\n",
    "\n",
    "        scores['G_loss_train'].append((g_loss/g_batch))\n",
    "        scores['D_loss_train'].append((d_loss/d_batch))\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        model.train(False)\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Beam search\n",
    "        print(\"Beam search...\")\n",
    "        # generated_sentences = beam_search(model.G, beam_iterator, vocab, config['beam_search'], device)\n",
    "        # generated_sentences = beam_search([model], beam_iterator, vocab, beam_size=config['beam_search']['beam_size'], max_len=config['beam_search']['max_len'], device=device)\n",
    "        generated_sentences = max_search(model, beam_iterator, vocab, max_len=config['beam_search']['max_len'], device=device)\n",
    "\n",
    "        # BLEU score\n",
    "        # for n in range(3,max_bleu):\n",
    "        #     score = bleu_score(references, generated_sentences, n+1)\n",
    "        #     bleus[n].append(score)\n",
    "        #     print(\"BLEU-{} score : {}\".format(n+1, score))\n",
    "        score = bleu_score(references, generated_sentences, max_bleu)\n",
    "        bleus[max_bleu-1].append(score)\n",
    "        print(\"BLEU-{} score : {}\".format(max_bleu, score))\n",
    "\n",
    "        if score > best_bleu[0]:\n",
    "            best_bleu = (score, epoch)\n",
    "            filename = 'output_epoch{}_bleu{}'.format(epoch,score)\n",
    "            out_file = os.path.join(output, filename)\n",
    "            torch.save(model.state_dict(), out_file)\n",
    "\n",
    "        print(\"Best BLEU so far : {} (Epoch {})\".format(best_bleu[0], best_bleu[1]))\n",
    "\n",
    "        if logging:\n",
    "            output_file = 'output_{}'.format(epoch)\n",
    "            output_sentences = os.path.join(output, output_file)\n",
    "            exh.write_text('\\n'.join(generated_sentences), output_sentences)\n",
    "\n",
    "        model.train(True)\n",
    "        torch.set_grad_enabled(True)\n",
    "        print(\"Epoch finished in {} seconds\".format(time.time()-secs))\n",
    "\n",
    "#         if epoch - best_bleu[1] == 3:\n",
    "#             break\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "\n",
    "    if logging:\n",
    "        scores['BLEU'] = bleus\n",
    "        output_scores = os.path.join(output, 'scores.json')\n",
    "        exh.write_json(scores, output_scores)\n",
    "        print(\"Scores saved in {}\".format(output_scores))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = check_args(sys.argv)\n",
    "    run(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6bbf15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:39:17.477589Z",
     "iopub.status.busy": "2024-04-03T04:39:17.477290Z",
     "iopub.status.idle": "2024-04-03T14:02:35.598602Z",
     "shell.execute_reply": "2024-04-03T14:02:35.597418Z"
    },
    "papermill": {
     "duration": 33798.131522,
     "end_time": "2024-04-03T14:02:35.601160",
     "exception": false,
     "start_time": "2024-04-03T04:39:17.469638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\r\n",
      "Training:   0%|                                         | 0/251 [00:00<?, ?it/s]/kaggle/working/code/models/wgan.py:117: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /usr/local/src/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)\r\n",
      "  fake = Variable(Tensor(real_samples.size(1), 1).fill_(1.0), requires_grad=False)\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.17226576910713395\r\n",
      "Best BLEU so far : 0.17226576910713395 (Epoch 1)\r\n",
      "Epoch finished in 1132.3388495445251 seconds\r\n",
      "Starting Epoch 2\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 2.5309502685218223e-11\r\n",
      "Best BLEU so far : 0.17226576910713395 (Epoch 1)\r\n",
      "Epoch finished in 1133.8990211486816 seconds\r\n",
      "Starting Epoch 3\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.24510880724039344\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1133.636801481247 seconds\r\n",
      "Starting Epoch 4\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.011421785184564586\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.7202942371368 seconds\r\n",
      "Starting Epoch 5\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.011421785184564586\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.7418162822723 seconds\r\n",
      "Starting Epoch 6\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "BLEU-4 score : 0\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.608743429184 seconds\r\n",
      "Starting Epoch 7\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.1752628192093507\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1126.2552707195282 seconds\r\n",
      "Starting Epoch 8\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.04947316032176487\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1125.3929092884064 seconds\r\n",
      "Starting Epoch 9\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.08797710234974905\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.960857629776 seconds\r\n",
      "Starting Epoch 10\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.08047188301249962\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1114.877736568451 seconds\r\n",
      "Starting Epoch 11\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.08047188301249962\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1111.992522239685 seconds\r\n",
      "Starting Epoch 12\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.07899470706347986\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1122.7955975532532 seconds\r\n",
      "Starting Epoch 13\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.011421785184564586\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1126.5771534442902 seconds\r\n",
      "Starting Epoch 14\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.011421785184564586\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.6530635356903 seconds\r\n",
      "Starting Epoch 15\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.08047188301249962\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1126.0297539234161 seconds\r\n",
      "Starting Epoch 16\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.04947316032176487\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1125.9972968101501 seconds\r\n",
      "Starting Epoch 17\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.24510880724039344\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.205168247223 seconds\r\n",
      "Starting Epoch 18\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.24510880724039344\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.5732107162476 seconds\r\n",
      "Starting Epoch 19\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.0059344919666367455\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1125.624171257019 seconds\r\n",
      "Starting Epoch 20\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "BLEU-4 score : 0\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1128.611466884613 seconds\r\n",
      "Starting Epoch 21\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.05475105203853251\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1125.818930864334 seconds\r\n",
      "Starting Epoch 22\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.11117437558124639\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1126.7668855190277 seconds\r\n",
      "Starting Epoch 23\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.0066002107268893885\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1128.932531118393 seconds\r\n",
      "Starting Epoch 24\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.03840871330193016\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1127.2101573944092 seconds\r\n",
      "Starting Epoch 25\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.03840871330193016\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1122.6427733898163 seconds\r\n",
      "Starting Epoch 26\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.03840871330193016\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1122.7557845115662 seconds\r\n",
      "Starting Epoch 27\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.03840871330193016\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1124.0317664146423 seconds\r\n",
      "Starting Epoch 28\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.14127817140507432\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1125.3285639286041 seconds\r\n",
      "Starting Epoch 29\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.14127817140507432\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1115.510570049286 seconds\r\n",
      "Starting Epoch 30\r\n",
      "Beam search...\r\n",
      "[0.25, 0.25, 0.25, 0.25]\r\n",
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \r\n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\r\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\r\n",
      "  warnings.warn(_msg)\r\n",
      "BLEU-4 score : 0.14127817140507432\r\n",
      "Best BLEU so far : 0.24510880724039344 (Epoch 3)\r\n",
      "Epoch finished in 1122.6373903751373 seconds\r\n",
      "Scores saved in output/results/scores.json\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/working/code/main.py /kaggle/working/config-kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c64a56",
   "metadata": {
    "papermill": {
     "duration": 0.604316,
     "end_time": "2024-04-03T14:02:36.820661",
     "exception": false,
     "start_time": "2024-04-03T14:02:36.216345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4715623,
     "sourceId": 8008551,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33811.313206,
   "end_time": "2024-04-03T14:02:37.715433",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-03T04:39:06.402227",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
